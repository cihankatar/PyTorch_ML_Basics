{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0,1,2,3,4,5]\n",
    "b=[34,23,34,45,56,45]\n",
    "\n",
    "print(f'\\n zip converts list to tuple ')\n",
    "for x in zip(a, b):\n",
    "    print(x,type(x))\n",
    "\n",
    "print(f'\\n zip converts list to int by one by')\n",
    "for x,y in zip(a, b):\n",
    "    print(x,type(x))\n",
    "\n",
    "print(f'\\n zip slice and converts list to tuple')\n",
    "for x in zip(a,a[1:3]):\n",
    "    print(x,type(x))\n",
    "\n",
    "print(f'\\n zip slice and converts list to int')\n",
    "for x,y in zip(a,a[1:3]):\n",
    "    print(x,type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Broadcast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 6, 8, 10]\n",
      "[[0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4]]\n",
      "[[0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4]]\n"
     ]
    }
   ],
   "source": [
    "#list Comprehension\n",
    "x = [1,2,3,4,5,6,7,8,9]\n",
    "x=np.array(x)\n",
    "x[x>=4]\n",
    "\n",
    "# ---------\n",
    "list = [i for i in range(11) if i % 2 == 0]\n",
    "print(list)\n",
    "\n",
    "# ---------\n",
    "\n",
    "matrix = [] \n",
    "for i in range(3):\n",
    "    # Append an empty sublist inside the list\n",
    "    matrix.append([])\n",
    "    for j in range(5):\n",
    "        matrix[i].append(j)\n",
    "print(matrix)\n",
    "\n",
    "# Nested list comprehension\n",
    "matrix = [[j for j in range(5)] for i in range(3)]\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterable object\n",
    "nums=[1,2,3,4,5,6]  #list object is an iterableble but not iterator\n",
    "print(dir(nums))\n",
    "nums=nums.__iter__() # or iter(nums)\n",
    "print(f'\\n', dir(nums))\n",
    "\n",
    "for i in range(5,10):\n",
    "    print(i)\n",
    "\n",
    "# list of vowels\n",
    "vowels = [\"a\", \"e\", \"i\", \"o\", \"u\"]\n",
    "# iter() with a list of vowels\n",
    "vowels_iter = iter(vowels)\n",
    "print(next(vowels_iter))\n",
    "print(next(vowels_iter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Module List  & Sequential \n",
    "'''\n",
    "The main difference between Sequential is that ModuleList have not a forward method so the inner layers are not connected. \n",
    "Assuming we need each output of each layer in the decoder, we can store it by:\n",
    "'''\n",
    "\n",
    "#Module List\n",
    "sizes=[1,16,32,32,64,128,64,32,32,1]\n",
    "layers = nn.ModuleList([nn.Linear(in_f, out_f) for in_f, out_f in zip(sizes, sizes[1:])])\n",
    "layers\n",
    "\n",
    "#Sequential #1\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyCNNClassifier(nn.Module):\n",
    "    def __init__(self, in_c, n_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.fc1 = nn.Linear(32 * 28 * 28, 1024)\n",
    "        self.fc2 = nn.Linear(1024, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1) # flat\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential #2\n",
    "def conv_block(in_f, out_f, *args, **kwargs):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_f, out_f, *args, **kwargs),\n",
    "        nn.BatchNorm2d(out_f),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "class MyCNNClassifier(nn.Module):\n",
    "    def __init__(self, in_c, n_classes):\n",
    "        super().__init__()\n",
    "        #self.conv_block1 = conv_block(in_c, 32, kernel_size=3, padding=1)\n",
    "        #self.conv_block2 = conv_block(32, 64, kernel_size=3, padding=1)\n",
    "        self.encoder = nn.Sequential(\n",
    "            conv_block(in_c, 32, kernel_size=3, padding=1),\n",
    "            conv_block(32, 64, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32 * 28 * 28, 1024),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(1024, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1) # flat\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MyCNNClassifier(1, 10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCNNClassifier(\n",
      "  (encoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (last): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Sequential #3\n",
    "def conv_block(in_f, out_f, *args, **kwargs):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_f, out_f, *args, **kwargs),\n",
    "        nn.BatchNorm2d(out_f),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "def dec_block(in_f, out_f):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_f, out_f),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "#Using * in front of a list expands out the members as individual arguments. So, the following two function calls will be equivalent:\n",
    "class MyCNNClassifier(nn.Module):\n",
    "    def __init__(self, in_c, enc_sizes, dec_sizes,  n_classes):\n",
    "        super().__init__()\n",
    "        self.enc_sizes = [in_c, *enc_sizes]  \n",
    "        self.dec_sizes = [32 * 28 * 28, *dec_sizes]\n",
    "\n",
    "        conv_blokcs = [conv_block(in_f, out_f, kernel_size=3, padding=1) \n",
    "                       for in_f, out_f in zip(self.enc_sizes, self.enc_sizes[1:])]\n",
    "        \n",
    "        self.encoder = nn.Sequential(*conv_blokcs)\n",
    "        \n",
    "        dec_blocks = [dec_block(in_f, out_f) \n",
    "                       for in_f, out_f in zip(self.dec_sizes, self.dec_sizes[1:])]\n",
    "\n",
    "        self.decoder = nn.Sequential(*dec_blocks)\n",
    "\n",
    "        self.last = nn.Linear(self.dec_sizes[-1], n_classes)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1) # flat\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "        \n",
    "model = MyCNNClassifier(1, [32,64], [1024, 512], 10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential #3\n",
    "def conv_block(in_f, out_f, *args, **kwargs):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_f, out_f, *args, **kwargs),\n",
    "        nn.BatchNorm2d(out_f),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "def dec_block(in_f, out_f):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_f, out_f),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "#Using * in front of a list expands out the members as individual arguments. So, the following two function calls will be equivalent:\n",
    "class MyCNNClassifier(nn.Module):\n",
    "    def __init__(self, in_c, enc_sizes, dec_sizes,  n_classes):\n",
    "        super().__init__()\n",
    "        self.enc_sizes = [in_c, *enc_sizes]  \n",
    "        self.dec_sizes = [32 * 28 * 28, *dec_sizes]\n",
    "\n",
    "        conv_blokcs = [conv_block(in_f, out_f, kernel_size=3, padding=1) \n",
    "                       for in_f, out_f in zip(self.enc_sizes, self.enc_sizes[1:])]\n",
    "        \n",
    "        self.encoder = nn.Sequential(*conv_blokcs)\n",
    "        \n",
    "        dec_blocks = [dec_block(in_f, out_f) \n",
    "                       for in_f, out_f in zip(self.dec_sizes, self.dec_sizes[1:])]\n",
    "\n",
    "        self.decoder = nn.Sequential(*dec_blocks)\n",
    "\n",
    "        self.last = nn.Linear(self.dec_sizes[-1], n_classes)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1) # flat\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "        \n",
    "model = MyCNNClassifier(1, [32,64], [1024, 512], 10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.0.0.weight Parameter containing:\n",
      "tensor([[[[ 9.5213e-02,  2.2351e-02,  5.4465e-03],\n",
      "          [ 2.9669e-01,  1.7940e-01,  7.8938e-02],\n",
      "          [ 4.9243e-02, -5.5768e-02,  2.7320e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2097e-01,  2.5328e-01,  2.9860e-01],\n",
      "          [-2.3578e-01, -1.2975e-01, -8.8945e-02],\n",
      "          [ 3.8957e-02, -2.2556e-01,  2.9031e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.2965e-01,  9.4832e-02, -2.5551e-01],\n",
      "          [-1.3072e-01,  3.2548e-01, -1.6421e-01],\n",
      "          [-1.8363e-01, -1.8384e-01,  1.1465e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.1495e-01,  3.6847e-02, -3.1536e-01],\n",
      "          [-1.5562e-01, -1.5061e-01,  1.9845e-01],\n",
      "          [ 1.8457e-01,  1.1846e-01, -1.3288e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.4959e-02,  2.3303e-01,  5.7756e-02],\n",
      "          [-3.1777e-01, -8.3749e-02, -1.8090e-01],\n",
      "          [-5.2558e-02,  8.9293e-02,  3.1711e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4324e-02,  1.6143e-01, -7.7496e-02],\n",
      "          [-1.7480e-02,  2.5939e-01,  1.2171e-02],\n",
      "          [-1.7159e-01,  4.5854e-02, -2.7592e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0391e-01,  6.2048e-02,  3.0598e-01],\n",
      "          [-2.6962e-01,  2.1803e-01,  1.0071e-01],\n",
      "          [-1.1458e-01, -2.4377e-01,  4.4759e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9341e-01, -1.9637e-01,  2.8437e-01],\n",
      "          [-5.3248e-02, -6.6098e-02, -8.5088e-02],\n",
      "          [ 1.0247e-01, -2.5134e-01,  2.4073e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.9009e-03,  2.1714e-01, -5.8750e-02],\n",
      "          [ 2.8777e-01, -7.0229e-02,  2.4607e-01],\n",
      "          [ 3.1678e-01, -1.9271e-01,  7.6266e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0273e-01, -1.7662e-01,  2.2798e-01],\n",
      "          [-3.2930e-03, -3.2048e-01, -3.1571e-01],\n",
      "          [-2.4931e-01,  2.2766e-02, -8.2410e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9769e-01, -1.4355e-02, -2.5819e-01],\n",
      "          [-9.3710e-02, -1.6867e-01,  1.4780e-01],\n",
      "          [ 1.9931e-01, -1.2576e-01, -1.3200e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.3061e-02,  6.9227e-03, -1.0445e-01],\n",
      "          [-1.2917e-01,  8.1435e-02, -1.3375e-01],\n",
      "          [ 1.4270e-01,  1.1819e-01, -1.7374e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4874e-01, -7.0099e-02,  2.0209e-01],\n",
      "          [ 2.0194e-01,  2.4677e-01, -2.0181e-01],\n",
      "          [-2.5179e-01, -1.9304e-01, -2.0540e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.2260e-01,  1.5676e-01, -3.0450e-01],\n",
      "          [-2.8350e-02,  3.2217e-01, -2.5649e-01],\n",
      "          [-1.3890e-01,  2.9161e-01,  2.6128e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2806e-01,  3.2445e-01, -3.6313e-03],\n",
      "          [ 1.5847e-01,  3.8342e-02, -5.7718e-02],\n",
      "          [ 1.4100e-01,  2.9889e-01, -2.8175e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7056e-01, -2.5279e-01, -1.2226e-01],\n",
      "          [ 3.7940e-02,  3.2133e-01, -1.2937e-01],\n",
      "          [ 2.5592e-01, -1.8030e-01,  2.5320e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3222e-01, -1.8479e-01,  2.4206e-01],\n",
      "          [-2.4881e-01,  2.0134e-01, -3.2759e-01],\n",
      "          [-5.5361e-02,  2.0556e-01,  2.4906e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2840e-01,  4.6618e-02,  9.3747e-02],\n",
      "          [-8.2489e-03, -1.6148e-01,  1.1061e-02],\n",
      "          [-4.5904e-02,  2.4059e-01, -2.0001e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8788e-01,  7.3507e-02,  6.8524e-02],\n",
      "          [ 2.0463e-01,  2.1268e-02,  7.7698e-02],\n",
      "          [-1.7863e-01,  1.6923e-01,  1.8281e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.6908e-01, -7.8701e-02, -2.0349e-01],\n",
      "          [ 1.4839e-01,  3.1968e-01,  1.1161e-01],\n",
      "          [-1.2752e-01, -3.1575e-01,  9.8380e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.2100e-02,  9.9082e-02,  8.3104e-02],\n",
      "          [-1.9185e-01,  4.8508e-02,  3.1283e-01],\n",
      "          [-7.1962e-02, -1.3553e-01,  1.9895e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1598e-01, -1.4933e-01, -2.4617e-04],\n",
      "          [ 1.2449e-01,  2.3819e-01,  6.7545e-02],\n",
      "          [ 3.0164e-01,  5.8124e-02, -4.4483e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9614e-03, -2.8222e-02, -1.6466e-01],\n",
      "          [ 2.3154e-01, -3.2826e-01,  1.6469e-02],\n",
      "          [ 3.2019e-01,  1.5181e-01, -2.8241e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.2597e-02,  2.7010e-01, -2.2942e-01],\n",
      "          [ 8.9450e-02,  2.1777e-02,  9.5543e-02],\n",
      "          [-6.6404e-02, -2.3151e-01, -7.5865e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.7256e-02,  1.8102e-01, -3.2486e-01],\n",
      "          [ 1.9662e-01, -8.4927e-02, -2.8676e-01],\n",
      "          [ 2.4959e-01, -1.0141e-01,  1.8176e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9785e-01,  5.8957e-02, -7.1471e-02],\n",
      "          [ 1.9684e-01, -1.1998e-01,  1.7669e-01],\n",
      "          [-1.5403e-01, -6.5553e-02,  1.1049e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.6060e-01, -1.6408e-01,  1.8246e-01],\n",
      "          [ 9.4255e-02, -3.1176e-01, -1.5040e-01],\n",
      "          [-1.6685e-01,  2.9946e-01,  1.0514e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3829e-01,  9.5705e-02, -1.9815e-01],\n",
      "          [ 7.3312e-02,  9.5921e-02,  8.6533e-02],\n",
      "          [ 2.7899e-01, -1.9659e-01, -2.3790e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1223e-01, -2.7913e-01,  2.3902e-01],\n",
      "          [-2.4472e-02, -9.0473e-02,  1.9541e-01],\n",
      "          [ 1.9656e-01,  8.0410e-02,  9.3580e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0342e-01,  1.9629e-01,  9.1329e-02],\n",
      "          [-1.0111e-01,  1.3899e-01, -9.5899e-02],\n",
      "          [-2.5674e-01,  1.7715e-01,  8.3182e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9795e-02,  2.5047e-01, -2.8794e-01],\n",
      "          [ 2.5520e-01,  1.1921e-01, -3.1733e-01],\n",
      "          [-2.8724e-01, -9.4604e-02, -1.1711e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0348e-01,  1.8451e-01,  3.0916e-01],\n",
      "          [ 2.0944e-01, -1.8330e-01, -1.2757e-01],\n",
      "          [-3.0716e-01,  2.6988e-01,  5.8461e-03]]]], requires_grad=True)\n",
      "encoder.0.0.bias Parameter containing:\n",
      "tensor([ 0.2511, -0.0934, -0.3324, -0.2164,  0.2709,  0.1285, -0.1942,  0.1675,\n",
      "         0.2211,  0.1702, -0.1559,  0.2211, -0.2820,  0.1064, -0.0902, -0.0367,\n",
      "         0.2393, -0.2707,  0.2913, -0.2089, -0.1774, -0.1742, -0.3212, -0.1383,\n",
      "        -0.1759,  0.0671,  0.1349,  0.0514,  0.1920, -0.0213,  0.0171,  0.0015],\n",
      "       requires_grad=True)\n",
      "encoder.0.1.weight Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True)\n",
      "encoder.0.1.bias Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "encoder.1.0.weight Parameter containing:\n",
      "tensor([[[[-4.2363e-02, -3.8535e-02, -1.0960e-02],\n",
      "          [-5.2490e-02, -5.1155e-02,  5.8685e-02],\n",
      "          [-4.4962e-02, -3.2139e-02,  5.2826e-02]],\n",
      "\n",
      "         [[-2.8166e-02,  1.4027e-02, -5.0937e-02],\n",
      "          [ 1.8704e-03, -5.8559e-03, -7.9071e-03],\n",
      "          [-8.1363e-03, -2.5300e-02,  3.5468e-02]],\n",
      "\n",
      "         [[-7.0267e-03,  4.7124e-02,  1.6631e-03],\n",
      "          [ 3.6836e-02, -3.2097e-02,  5.7282e-02],\n",
      "          [ 1.2318e-02,  1.0419e-02, -3.5002e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.2310e-02, -1.8945e-02, -8.4091e-03],\n",
      "          [ 2.8437e-02,  3.4730e-02, -6.8463e-03],\n",
      "          [ 2.7206e-02,  1.5468e-02,  2.8728e-02]],\n",
      "\n",
      "         [[ 5.4247e-02,  4.7450e-02,  2.3618e-02],\n",
      "          [ 5.5473e-02, -7.1571e-03,  3.1011e-02],\n",
      "          [ 3.8243e-02,  4.2185e-02,  3.1335e-03]],\n",
      "\n",
      "         [[-2.5547e-03,  1.9355e-02,  3.8497e-02],\n",
      "          [ 4.7712e-02,  3.2969e-02,  5.1930e-02],\n",
      "          [-5.8323e-02,  3.2401e-02,  2.8847e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0506e-02, -5.4923e-02,  2.8937e-02],\n",
      "          [-2.9428e-02,  5.4750e-02,  4.9712e-02],\n",
      "          [ 4.5438e-02,  3.4580e-02, -5.5364e-03]],\n",
      "\n",
      "         [[ 3.5295e-02,  1.4158e-02, -3.2486e-02],\n",
      "          [-2.7965e-02,  1.8073e-02,  5.2312e-02],\n",
      "          [-5.6432e-02,  3.3719e-02, -7.2155e-03]],\n",
      "\n",
      "         [[ 4.9747e-02, -2.2652e-02,  1.5299e-02],\n",
      "          [ 4.9454e-03, -1.0577e-02,  5.9944e-03],\n",
      "          [ 8.0317e-04,  6.5797e-03, -1.4434e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3451e-02, -1.4783e-02,  2.0429e-03],\n",
      "          [-8.4797e-03,  3.8332e-02,  2.2681e-02],\n",
      "          [-3.7624e-02, -4.1502e-03, -1.9260e-03]],\n",
      "\n",
      "         [[-2.3696e-02, -4.9182e-02,  5.6571e-02],\n",
      "          [ 4.3198e-02,  2.4855e-02,  1.4696e-02],\n",
      "          [ 1.3620e-02, -1.1571e-02, -3.2977e-02]],\n",
      "\n",
      "         [[ 2.0097e-03,  2.8029e-03, -2.3971e-02],\n",
      "          [ 2.6955e-02,  1.9189e-02, -1.0933e-02],\n",
      "          [-4.5132e-02, -9.3310e-03, -3.9395e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8956e-02, -2.6365e-02, -5.6416e-02],\n",
      "          [ 2.4675e-02,  3.0999e-02,  2.4874e-02],\n",
      "          [-5.0390e-02,  2.8666e-02, -4.1859e-02]],\n",
      "\n",
      "         [[-5.4273e-03, -1.5388e-02, -4.1323e-02],\n",
      "          [-2.0583e-02,  1.3499e-02,  3.7704e-02],\n",
      "          [-3.1374e-03,  1.4684e-02,  2.9460e-03]],\n",
      "\n",
      "         [[-2.6134e-02,  5.8293e-02, -3.2883e-02],\n",
      "          [-3.8634e-02, -1.0987e-02, -3.8656e-02],\n",
      "          [ 3.6616e-02, -4.7393e-02, -5.3466e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.5753e-02, -2.0052e-02,  5.0508e-02],\n",
      "          [ 2.4778e-02, -4.8252e-02,  4.5722e-02],\n",
      "          [ 4.5242e-02,  4.8250e-02, -2.4613e-02]],\n",
      "\n",
      "         [[ 5.6148e-02, -4.3753e-02, -5.2702e-02],\n",
      "          [-1.2553e-02, -1.2059e-02, -3.6898e-02],\n",
      "          [-2.4359e-02,  2.7577e-03,  3.5308e-02]],\n",
      "\n",
      "         [[ 1.2115e-03, -3.5153e-03, -1.2485e-02],\n",
      "          [ 5.3912e-02,  4.2190e-03,  1.4639e-02],\n",
      "          [ 1.2600e-02,  5.0495e-03,  6.0591e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.9577e-02, -2.1837e-02,  5.8268e-02],\n",
      "          [ 3.6921e-02,  4.5369e-02, -4.2764e-02],\n",
      "          [ 3.7244e-02, -9.0959e-03, -4.1440e-02]],\n",
      "\n",
      "         [[-3.8442e-02, -5.4976e-02, -2.6192e-02],\n",
      "          [-5.8578e-02, -3.6374e-02, -4.0094e-03],\n",
      "          [-1.2939e-02,  9.2514e-03, -4.1047e-03]],\n",
      "\n",
      "         [[-2.1759e-02, -2.9675e-02,  3.5136e-02],\n",
      "          [ 4.9959e-02, -1.8077e-03, -4.5326e-02],\n",
      "          [ 2.9867e-02, -1.9484e-02,  4.4003e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.3177e-02, -4.2340e-02, -1.7305e-02],\n",
      "          [-4.9104e-02, -1.6351e-02,  1.6869e-02],\n",
      "          [-2.3854e-02, -3.1507e-02,  1.6178e-02]],\n",
      "\n",
      "         [[ 4.8578e-02, -5.1659e-02, -4.3143e-05],\n",
      "          [ 2.0339e-02,  5.6002e-02, -5.7455e-02],\n",
      "          [ 3.9974e-02, -3.1254e-02,  1.9313e-02]],\n",
      "\n",
      "         [[ 2.8650e-03,  4.9089e-03,  6.0496e-03],\n",
      "          [ 5.3953e-02, -3.2091e-02,  1.3634e-02],\n",
      "          [-2.2387e-02,  2.5291e-02, -1.3044e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9375e-02, -3.2740e-02, -4.7565e-02],\n",
      "          [ 8.6427e-03,  3.4981e-03, -5.6030e-02],\n",
      "          [-1.0875e-02,  2.2561e-02, -1.3531e-02]],\n",
      "\n",
      "         [[-2.6877e-02, -4.4041e-02,  4.9449e-02],\n",
      "          [-1.7068e-02, -5.4501e-02, -3.7064e-02],\n",
      "          [ 2.8654e-02,  3.4070e-02,  1.8855e-02]],\n",
      "\n",
      "         [[ 1.0958e-02, -6.8244e-03,  5.4733e-02],\n",
      "          [-9.1512e-03,  5.4027e-02, -1.4586e-02],\n",
      "          [ 8.1394e-03,  3.9501e-02, -7.9550e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4400e-02, -5.6362e-02,  1.4566e-02],\n",
      "          [ 2.2105e-03,  3.4709e-02, -2.4944e-03],\n",
      "          [-5.0543e-03, -9.6076e-03,  5.0924e-02]],\n",
      "\n",
      "         [[ 5.6993e-02, -2.6585e-02, -3.3870e-02],\n",
      "          [-8.6785e-03,  5.4352e-02,  1.4507e-02],\n",
      "          [-1.9610e-02, -1.2506e-03,  5.7241e-02]],\n",
      "\n",
      "         [[-4.5178e-02, -1.9488e-02,  2.1087e-02],\n",
      "          [-2.6756e-02,  5.7245e-02, -3.7507e-02],\n",
      "          [-4.7323e-02,  6.0455e-03, -2.0702e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6428e-02, -2.9481e-02, -5.7424e-02],\n",
      "          [-3.4641e-02, -4.2469e-02,  5.7903e-02],\n",
      "          [-5.8514e-02, -5.1281e-02, -9.3703e-03]],\n",
      "\n",
      "         [[ 1.9188e-02,  5.7222e-02,  1.0242e-02],\n",
      "          [ 4.4770e-02, -3.6537e-02, -4.8204e-02],\n",
      "          [-2.1334e-02,  4.3333e-02, -1.7365e-02]],\n",
      "\n",
      "         [[-3.2471e-02, -5.8293e-02, -2.8490e-02],\n",
      "          [-4.9998e-03, -2.4701e-03, -1.2487e-03],\n",
      "          [-3.2376e-02, -1.2103e-02,  2.8148e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5141e-02,  2.4693e-02, -3.1735e-02],\n",
      "          [ 3.2273e-02, -3.9450e-02,  4.1323e-02],\n",
      "          [-2.4187e-02,  5.5542e-02,  2.9296e-02]],\n",
      "\n",
      "         [[ 2.7614e-02, -5.7026e-02,  1.0726e-02],\n",
      "          [-2.3847e-02, -2.4375e-02,  5.4836e-02],\n",
      "          [ 2.3097e-02,  4.8966e-03,  1.4456e-02]],\n",
      "\n",
      "         [[ 1.5068e-03, -6.1945e-03,  2.7382e-02],\n",
      "          [-2.9654e-03,  9.5745e-03, -5.7054e-03],\n",
      "          [-4.2064e-02,  5.8166e-02,  4.7602e-03]]]], requires_grad=True)\n",
      "encoder.1.0.bias Parameter containing:\n",
      "tensor([-0.0237,  0.0384, -0.0536,  0.0222, -0.0293, -0.0447,  0.0440, -0.0483,\n",
      "         0.0452, -0.0562, -0.0003, -0.0580, -0.0075,  0.0209,  0.0345,  0.0536,\n",
      "        -0.0404, -0.0332, -0.0371,  0.0134,  0.0063, -0.0355, -0.0182,  0.0384,\n",
      "        -0.0200, -0.0338,  0.0216, -0.0482, -0.0496, -0.0227, -0.0294, -0.0178,\n",
      "         0.0389,  0.0264,  0.0464, -0.0332, -0.0138, -0.0028, -0.0534, -0.0153,\n",
      "         0.0008,  0.0368,  0.0525,  0.0299,  0.0540,  0.0216,  0.0136,  0.0161,\n",
      "        -0.0263,  0.0410, -0.0042,  0.0191, -0.0361,  0.0277,  0.0241,  0.0002,\n",
      "        -0.0484,  0.0300, -0.0087,  0.0577,  0.0556, -0.0028, -0.0578, -0.0323],\n",
      "       requires_grad=True)\n",
      "encoder.1.1.weight Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "encoder.1.1.bias Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "decoder.0.0.weight Parameter containing:\n",
      "tensor([[-2.0000e-03,  5.6405e-05,  1.1742e-03,  ..., -2.7075e-03,\n",
      "          1.3796e-04, -5.4440e-03],\n",
      "        [ 7.7175e-04, -5.0382e-03,  3.5612e-03,  ...,  5.2300e-03,\n",
      "          4.7847e-04, -6.2940e-03],\n",
      "        [-3.6534e-03,  3.2400e-03,  2.8498e-03,  ...,  2.8593e-03,\n",
      "         -6.2557e-03,  4.5840e-03],\n",
      "        ...,\n",
      "        [-5.7969e-04,  1.1371e-03, -4.8070e-03,  ...,  4.9134e-04,\n",
      "          4.5840e-03,  3.6095e-03],\n",
      "        [-3.3289e-03, -4.2413e-03,  3.3770e-03,  ...,  2.5179e-03,\n",
      "          4.7742e-03,  4.8853e-03],\n",
      "        [-2.2403e-03, -4.7821e-04, -1.7322e-03,  ..., -1.8469e-04,\n",
      "          2.6152e-03,  5.5546e-03]], requires_grad=True)\n",
      "decoder.0.0.bias Parameter containing:\n",
      "tensor([-0.0028,  0.0030,  0.0051,  ..., -0.0030,  0.0047,  0.0021],\n",
      "       requires_grad=True)\n",
      "decoder.1.0.weight Parameter containing:\n",
      "tensor([[-0.0262,  0.0300,  0.0303,  ...,  0.0194, -0.0178,  0.0075],\n",
      "        [ 0.0199, -0.0243,  0.0011,  ...,  0.0092, -0.0226, -0.0271],\n",
      "        [ 0.0095,  0.0043, -0.0161,  ...,  0.0248,  0.0145, -0.0229],\n",
      "        ...,\n",
      "        [ 0.0046,  0.0249,  0.0265,  ..., -0.0229,  0.0070,  0.0234],\n",
      "        [-0.0182,  0.0173, -0.0171,  ..., -0.0058, -0.0013,  0.0309],\n",
      "        [ 0.0209, -0.0150, -0.0113,  ..., -0.0185, -0.0279, -0.0095]],\n",
      "       requires_grad=True)\n",
      "decoder.1.0.bias Parameter containing:\n",
      "tensor([ 2.5736e-02,  1.3685e-02,  6.2195e-03, -1.6392e-02, -1.6818e-02,\n",
      "        -1.3843e-02, -1.7619e-03, -5.5088e-03, -1.6647e-02,  2.5079e-02,\n",
      "        -1.7293e-02, -3.0027e-03, -1.6415e-02, -2.6969e-02, -2.1613e-02,\n",
      "        -2.9807e-02, -5.7378e-03, -4.6248e-03,  9.2842e-03,  1.3043e-02,\n",
      "        -2.7348e-02,  1.4674e-02, -2.6185e-02,  5.3574e-03, -1.4904e-02,\n",
      "         2.8321e-02, -1.2673e-02, -2.4663e-02,  4.5694e-03,  7.0374e-03,\n",
      "        -1.0757e-02,  1.2932e-02, -2.3733e-02,  1.7256e-02,  1.6361e-02,\n",
      "        -2.3930e-02, -2.9111e-02, -1.4489e-03, -1.3427e-02,  1.2593e-02,\n",
      "         9.6691e-03, -9.1384e-03,  2.6965e-02, -2.9976e-02, -8.0085e-03,\n",
      "        -2.6568e-02,  1.5497e-02, -1.7209e-02, -2.8953e-02, -8.8377e-04,\n",
      "        -2.5812e-03,  9.2804e-03, -1.6876e-02, -2.6453e-02, -3.1107e-02,\n",
      "         1.9403e-02,  2.4472e-02,  1.3867e-02,  1.2582e-03, -1.7401e-03,\n",
      "        -6.8640e-04,  1.6188e-04, -1.6803e-02, -1.5219e-02,  6.5458e-03,\n",
      "         1.1647e-02, -5.5951e-03, -1.1802e-02, -2.1555e-02,  7.0172e-03,\n",
      "         7.0602e-03, -1.7900e-02,  1.3323e-02,  2.0663e-02, -6.3736e-03,\n",
      "         4.5189e-03, -2.0179e-02,  3.0031e-02, -2.8340e-02,  1.6122e-02,\n",
      "         1.5272e-02, -1.5918e-02,  2.7645e-02, -1.5977e-02, -1.2819e-03,\n",
      "        -2.4326e-02,  2.6160e-02,  2.6609e-02,  2.3640e-02,  1.2239e-02,\n",
      "        -2.9801e-02,  2.2531e-02, -1.6033e-02,  8.6341e-03,  2.4687e-02,\n",
      "        -2.5343e-02,  7.8316e-03,  3.5766e-03, -2.4141e-02, -2.1171e-02,\n",
      "         4.3106e-03, -2.5148e-02,  9.4645e-04, -7.9468e-04, -2.6116e-02,\n",
      "        -1.0882e-02,  2.7882e-02, -8.1975e-03, -1.0852e-03, -2.1364e-02,\n",
      "        -1.3365e-02, -2.8427e-02, -6.8533e-03, -2.3724e-02,  2.0870e-02,\n",
      "        -1.7987e-02,  3.0465e-02,  2.4156e-02, -9.6173e-04,  5.9383e-03,\n",
      "        -2.9722e-02,  2.0164e-02,  2.8453e-03, -2.3143e-03, -1.7279e-02,\n",
      "        -7.1968e-03,  1.9576e-02,  4.7532e-03,  1.0797e-02, -8.6093e-03,\n",
      "        -1.2114e-02, -5.0404e-04,  3.0023e-03,  1.6185e-02, -3.1395e-03,\n",
      "         2.6788e-02, -2.7509e-02, -2.4827e-02, -1.1732e-02, -7.9986e-03,\n",
      "        -6.2680e-03, -3.0003e-02, -8.9301e-03, -1.0276e-02,  1.1878e-02,\n",
      "         1.6625e-02,  2.6968e-02,  2.9868e-02,  1.1300e-02,  1.3857e-02,\n",
      "        -1.5249e-02,  2.8383e-02, -2.4623e-02,  2.9220e-03, -2.8869e-02,\n",
      "        -2.4926e-02,  1.6117e-02, -2.9427e-02,  7.5262e-03,  2.9215e-02,\n",
      "        -1.7095e-02,  2.9043e-02,  2.2017e-02,  2.6865e-02, -6.0043e-03,\n",
      "         2.1295e-03, -1.9389e-02, -3.3815e-03, -1.5054e-02,  3.7879e-03,\n",
      "        -2.5352e-02,  1.5091e-02,  2.8182e-02, -5.9202e-05,  6.0738e-03,\n",
      "        -3.8451e-03,  3.6962e-03,  1.6754e-02,  4.6425e-03, -6.4029e-03,\n",
      "         1.4638e-02, -1.2251e-02, -1.3172e-02, -6.9587e-03,  2.6509e-03,\n",
      "        -5.8247e-03, -1.6365e-02,  2.5104e-02, -1.9480e-02, -4.6404e-03,\n",
      "         2.9622e-02, -1.6041e-02,  1.3148e-03,  1.5595e-03, -1.5717e-02,\n",
      "        -2.0867e-02,  8.9543e-03, -1.6225e-02,  2.6588e-02, -6.9800e-03,\n",
      "         2.9954e-02,  1.5136e-02,  2.6567e-03,  1.5983e-02,  2.3632e-02,\n",
      "        -1.8847e-02, -4.0753e-03,  1.8744e-02, -2.3238e-02, -3.2202e-03,\n",
      "        -9.1203e-03, -1.3796e-02, -2.7567e-02, -2.6423e-02, -9.4653e-03,\n",
      "        -2.3829e-02, -1.6119e-02, -1.9052e-02,  4.2856e-03,  2.7138e-02,\n",
      "         8.9845e-03,  3.0187e-02,  2.0059e-02,  1.3127e-02, -1.2114e-02,\n",
      "         2.6022e-02, -4.3448e-03, -2.3895e-02,  1.9729e-02,  2.5503e-02,\n",
      "        -4.5147e-03, -1.9787e-02,  2.7436e-02,  1.0857e-03,  5.8548e-03,\n",
      "        -2.2927e-02,  2.9376e-02, -2.7034e-02, -2.8049e-02, -1.5550e-02,\n",
      "        -8.9324e-03, -1.5829e-02,  2.0406e-02,  7.0663e-03, -1.6532e-02,\n",
      "        -2.5370e-03,  2.7224e-03, -2.0548e-02, -1.4520e-02,  4.7481e-03,\n",
      "         1.2949e-02, -9.0311e-03,  2.7340e-02,  3.7489e-03,  2.0422e-02,\n",
      "         2.2655e-02,  1.2333e-02,  2.6848e-02,  3.6741e-03,  1.6012e-02,\n",
      "        -2.5899e-02,  1.1101e-02,  1.6779e-02, -1.5478e-02, -2.9415e-02,\n",
      "         2.2500e-02,  1.5964e-02, -1.1076e-02,  2.4036e-02, -1.6380e-02,\n",
      "        -5.8764e-03,  7.7835e-03, -2.8780e-02,  7.5362e-03, -1.4078e-02,\n",
      "         6.8353e-03,  5.1731e-03, -1.1703e-02,  1.3569e-02, -1.9831e-02,\n",
      "        -1.5687e-02, -9.4086e-03, -2.7962e-02,  1.1467e-02, -2.4787e-02,\n",
      "         1.2255e-02,  2.1524e-02,  1.4309e-02,  3.0873e-02,  2.4481e-02,\n",
      "         2.4251e-02,  9.6835e-03,  2.2074e-02,  2.1505e-02, -1.7033e-02,\n",
      "         7.4273e-03,  3.9557e-04,  1.8530e-02,  2.0750e-02, -1.4845e-02,\n",
      "         3.1040e-02, -8.1199e-03, -1.2181e-03, -9.0327e-03,  1.5996e-02,\n",
      "         2.4529e-02,  1.2900e-02, -2.6046e-03,  1.1084e-02,  1.7257e-02,\n",
      "         2.1148e-02, -4.6723e-03, -1.4095e-02, -2.5496e-02, -1.1275e-04,\n",
      "         1.3751e-02,  3.1094e-02,  2.1620e-03,  1.1066e-02, -1.7392e-02,\n",
      "        -8.4562e-03, -7.7659e-03, -7.5735e-03, -2.7643e-02,  4.2710e-03,\n",
      "         2.6164e-02, -1.1950e-02,  3.2457e-03,  2.3128e-02,  6.3484e-03,\n",
      "        -8.3857e-03,  6.1651e-03, -2.1777e-02, -5.7813e-03,  9.2102e-03,\n",
      "         1.5613e-02,  2.1100e-02, -2.9990e-02,  2.9989e-02, -6.5384e-03,\n",
      "        -1.7005e-02, -1.9026e-02, -2.9463e-02, -2.1722e-02, -2.9839e-03,\n",
      "        -2.7813e-02, -1.1838e-03, -1.6307e-02,  2.7796e-02,  2.4294e-02,\n",
      "        -2.1932e-02,  1.8940e-02, -3.1085e-02, -2.7611e-02,  3.9697e-03,\n",
      "         1.6431e-02,  8.2527e-04,  4.9638e-03, -2.4407e-03,  2.7738e-02,\n",
      "        -1.2671e-02,  2.8214e-02, -1.1828e-02,  6.3761e-03, -9.7897e-03,\n",
      "         1.2981e-02, -2.6373e-02, -1.4147e-02,  1.2695e-02, -1.6625e-02,\n",
      "        -8.2080e-03,  2.3718e-03,  1.0883e-02,  1.7290e-02, -2.8405e-02,\n",
      "         2.4482e-02, -2.7665e-02,  6.1118e-03, -1.6599e-02, -9.3765e-03,\n",
      "        -1.3694e-02, -2.9316e-02,  1.7176e-02, -2.1475e-02,  3.1864e-03,\n",
      "         9.5396e-03,  2.3937e-02,  1.9424e-03,  1.8955e-02, -1.9485e-02,\n",
      "        -2.0610e-02, -6.7791e-04, -3.3391e-03, -5.6573e-03,  1.3425e-03,\n",
      "         2.7710e-02,  8.6235e-03,  2.5993e-02,  7.8217e-03,  1.5307e-02,\n",
      "         6.5260e-03,  3.0812e-02, -2.8587e-02,  1.8866e-02,  2.1898e-02,\n",
      "         6.4445e-03, -2.2106e-02, -1.0845e-02, -1.8065e-02, -2.2335e-02,\n",
      "        -3.1391e-03, -2.1489e-02, -2.1914e-02,  1.4643e-02,  1.5037e-02,\n",
      "        -2.4851e-02, -2.5750e-02,  1.6041e-02, -2.4432e-02, -1.0611e-02,\n",
      "        -2.2804e-02, -3.0072e-02, -5.7451e-03, -1.8267e-02, -2.4222e-02,\n",
      "        -2.0700e-03, -2.2203e-02,  2.6804e-02,  1.7564e-02,  3.0822e-02,\n",
      "        -1.8665e-02, -2.0407e-02,  9.7792e-03,  2.9489e-02,  2.3427e-02,\n",
      "         2.3702e-02, -7.3980e-03,  2.9455e-02, -3.0532e-02, -1.1964e-02,\n",
      "        -6.0131e-03,  1.2362e-02,  2.2231e-02, -8.6757e-03,  1.0561e-02,\n",
      "         8.8150e-04, -2.2401e-03, -1.2033e-02, -2.7924e-02,  4.4042e-03,\n",
      "        -1.1674e-02, -6.5594e-03, -1.5546e-02, -2.0419e-02, -1.8036e-02,\n",
      "        -9.8787e-03, -1.3751e-02,  1.1389e-02, -6.8868e-03, -7.9602e-03,\n",
      "         3.8667e-03,  1.4446e-02, -2.2707e-02,  1.9073e-02, -2.9040e-02,\n",
      "         3.8417e-03, -2.8629e-02, -2.0328e-02,  8.0836e-03, -1.2451e-02,\n",
      "        -1.7101e-02,  2.8874e-02,  5.3300e-03, -1.7069e-02, -2.1094e-02,\n",
      "        -4.9719e-03, -2.8503e-02,  2.7935e-02,  2.6437e-03,  1.2080e-03,\n",
      "        -1.8763e-02,  2.5581e-02, -2.6809e-02, -2.4918e-02, -2.2188e-02,\n",
      "         2.0637e-02, -1.5536e-02,  1.7511e-02, -2.7166e-02,  4.5117e-03,\n",
      "         1.9948e-02, -1.8836e-02, -2.1141e-02,  1.1244e-02,  2.7055e-02,\n",
      "        -2.0660e-02,  2.6623e-02,  1.7492e-03, -2.6828e-02, -1.1548e-02,\n",
      "         3.0686e-02,  8.5811e-03, -6.9432e-04, -1.4071e-02, -1.0716e-02,\n",
      "        -2.4765e-02,  6.0649e-03,  6.0775e-03,  1.3785e-02, -6.0683e-03,\n",
      "         3.4932e-03, -1.9332e-02], requires_grad=True)\n",
      "last.weight Parameter containing:\n",
      "tensor([[-0.0421, -0.0432,  0.0404,  ...,  0.0374,  0.0163,  0.0329],\n",
      "        [ 0.0082, -0.0123, -0.0043,  ..., -0.0252,  0.0010, -0.0411],\n",
      "        [-0.0111,  0.0335,  0.0019,  ...,  0.0156, -0.0289,  0.0197],\n",
      "        ...,\n",
      "        [-0.0034,  0.0233, -0.0350,  ..., -0.0246,  0.0399,  0.0411],\n",
      "        [ 0.0097,  0.0374, -0.0327,  ...,  0.0199,  0.0304,  0.0304],\n",
      "        [ 0.0311, -0.0394,  0.0292,  ...,  0.0336,  0.0024, -0.0226]],\n",
      "       requires_grad=True)\n",
      "last.bias Parameter containing:\n",
      "tensor([ 1.9635e-02,  7.4547e-05, -2.4291e-02, -2.1896e-02, -1.8992e-02,\n",
      "         8.2786e-03,  4.0265e-02,  5.8474e-03,  2.5403e-02,  1.7040e-02],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
