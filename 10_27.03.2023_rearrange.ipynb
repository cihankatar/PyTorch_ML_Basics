{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##IMPORT \n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from glob import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 15, 20, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "# suppose we have a set of 32 images in \"h w c\" format (height-width-channel)\n",
    "images = [np.random.randn(30, 40, 3) for _ in range(32)]\n",
    "\n",
    "# stack along first (batch) axis, output is a single array\n",
    "rearrange(images, 'b h w c -> b h w c').shape\n",
    "(32, 30, 40, 3)\n",
    "\n",
    "# concatenate images along height (vertical axis), 960 = 32 * 30\n",
    "rearrange(images, 'b h w c -> (b h) w c').shape\n",
    "(960, 40, 3)\n",
    "\n",
    "# concatenated images along horizontal axis, 1280 = 32 * 40\n",
    "rearrange(images, 'b h w c -> h (b w) c').shape\n",
    "(30, 1280, 3)\n",
    "\n",
    "# reordered axes to \"b c h w\" format for deep learning\n",
    "rearrange(images, 'b h w c -> b c h w').shape\n",
    "(32, 3, 30, 40)\n",
    "\n",
    "# flattened each image into a vector, 3600 = 30 * 40 * 3\n",
    "rearrange(images, 'b h w c -> b (c h w)').shape\n",
    "(32, 3600)\n",
    "\n",
    "# split each image into 4 smaller (top-left, top-right, bottom-left, bottom-right), 128 = 32 * 2 * 2\n",
    "rearrange(images, 'b (h1 h) (w1 w) c -> (b h1 w1) h w c', h1=2, w1=2).shape\n",
    "(128, 15, 20, 3)\n",
    "\n",
    "# space-to-depth operation\n",
    "rearrange(images, 'b (h h1) (w w1) c -> b h w (c h1 w1)', h1=2, w1=2).shape\n",
    "(32, 15, 20, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
