{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##IMPORT \n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from glob import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_manuel(input):\n",
    "    return (torch.exp(input).t() / torch.sum(torch.exp(input),dim=1)).t()\n",
    "    #(torch.exp(z.t()) / torch.sum(torch.exp(z), dim=1)).t()\n",
    "\n",
    "def CE_loss_manuel(input,target):\n",
    "    return torch.mean(-torch.sum(torch.log(softmax_manuel(input)) * (target),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Case\n",
    "\n",
    "crossentropy=nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "a=torch.tensor([[0.2, 0.3, 2, 3],\n",
    "                [0.6, 0.5, 4, 4]])\n",
    "\n",
    "print(a.shape)\n",
    "\n",
    "c=torch.tensor([[0, 0, 0, 1],\n",
    "                [0, 0, 0, 1]])\n",
    "print(c.shape)\n",
    "\n",
    "b=torch.tensor( [3,\n",
    "                 3])\n",
    "print(b.shape)\n",
    "\n",
    "loss_manuel    = CE_loss_manuel(a,c)\n",
    "loss_function  = crossentropy(a,b)\n",
    "\n",
    "print(loss_manuel,loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D case\n",
    "\n",
    "\n",
    "a_3d=torch.tensor([[[0.2,0.3,2,3],\n",
    "                 [0.6,0.5,4,4]],\n",
    "                 \n",
    "                [[0.2,0.3,2,3],\n",
    "                 [0.6,0.5,4,4]]])\n",
    "\n",
    "c_3d=torch.tensor([[[0,0,0,1],\n",
    "                 [0,0,0,1]],\n",
    "                \n",
    "                [[0,0,0,1],\n",
    "                 [0,0,0,1]]])\n",
    "\n",
    "b_3d=torch.tensor ([[3,\n",
    "                  3],\n",
    "\n",
    "                 [3,\n",
    "                  3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 4]) torch.Size([2, 2]) torch.Size([2, 2, 4])\n",
      "torch.Size([4, 4])\n",
      "torch.Size([4, 4])\n",
      "torch.Size([4])\n",
      "tensor(0.5636) tensor(0.5636)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(a_3d.shape,b_3d.shape,c_3d.shape)\n",
    "\n",
    "last_dim = torch.tensor(a_3d.shape[:-1])\n",
    "last_dim = torch.prod(last_dim)\n",
    "last_dim\n",
    "\n",
    "a_flat = a_3d.view(last_dim,-1) \n",
    "print(a_flat.shape)\n",
    "\n",
    "c_flat = c_3d.view(last_dim,-1) \n",
    "print(c_flat.shape)\n",
    "\n",
    "b_flat = b_3d.view(last_dim) \n",
    "print(b_flat.shape)\n",
    "\n",
    "loss_function  = crossentropy(a_flat,b_flat)  # we got same result like 2d case since we reduced as 'mean'\n",
    "loss_manuel  = CE_loss_manuel(a_flat,c_flat)  # we got same result like 2d case since we reduced as 'mean' manually\n",
    "print(loss_function,loss_manuel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
