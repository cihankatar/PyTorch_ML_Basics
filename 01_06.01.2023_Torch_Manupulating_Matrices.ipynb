{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as  np\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2],\n",
    "                  [3,4]])\n",
    "                  \n",
    "b = torch.tensor([[5,6],\n",
    "                  [7,8]])\n",
    "c = a@b #For dot product\n",
    "print(c)\n",
    "\n",
    "d = a*b #For elementwise multiplication \n",
    "print(d)\n",
    "print(c)\n",
    "\n",
    "#in numpy it is used np.dot\n",
    "'''\n",
    "a = np.arange(3*4*5*6).reshape((3,4,5,6))\n",
    "b = np.arange(3*4*5*6)[::-1].reshape((5,4,6,3))\n",
    "np.dot(a, b)[2,3,2,1,2,2]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " elementwise a,b \n",
      " tensor([[3.1748, 3.9220],\n",
      "        [1.0424, 0.2190],\n",
      "        [0.8258, 1.0702]])\n",
      "\n",
      " dotproduct a,x \n",
      "= tensor([[43, 99, 65],\n",
      "        [22, 54, 38],\n",
      "        [16, 36, 23]])\n",
      "concatinating a and b in axis 0\n",
      " tensor([[5.0000, 9.0000],\n",
      "        [2.0000, 6.0000],\n",
      "        [2.0000, 3.0000],\n",
      "        [0.6350, 0.4358],\n",
      "        [0.5212, 0.0365],\n",
      "        [0.4129, 0.3567]])\n",
      "\n",
      "concatinating a and b in axis 1\n",
      " tensor([[5.0000, 9.0000, 0.6350, 0.4358],\n",
      "        [2.0000, 6.0000, 0.5212, 0.0365],\n",
      "        [2.0000, 3.0000, 0.4129, 0.3567]])\n",
      "a : tensor([[5, 9],\n",
      "        [2, 6],\n",
      "        [2, 3]])\n",
      " \n",
      " slicing a[:,0] =  torch.Size([3])\n",
      " :\n",
      " slice_a_keep_dim a[:, 0:1] =  torch.Size([3, 1])\n",
      "tensor([[5, 9],\n",
      "        [2, 6],\n",
      "        [2, 3]])\n",
      "torch.Size([3, 2])\n",
      "\n",
      "sum = tensor(27)\n",
      "\n",
      "sum and keep dim = tensor([[14],\n",
      "        [ 8],\n",
      "        [ 5]])\n",
      "\n",
      "sum and keep dim = tensor([ 9, 18])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/cihankatar/Desktop/Github_Repo/PyTorch_Practising/01_06.01.2023_Torch_Manupulating_Matrices.ipynb Cell 3\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cihankatar/Desktop/Github_Repo/PyTorch_Practising/01_06.01.2023_Torch_Manupulating_Matrices.ipynb#W2sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39msum and keep dim =\u001b[39m\u001b[39m'\u001b[39m,sum_axis)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cihankatar/Desktop/Github_Repo/PyTorch_Practising/01_06.01.2023_Torch_Manupulating_Matrices.ipynb#W2sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m#mean for each of dim ---------------------------------------------------\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cihankatar/Desktop/Github_Repo/PyTorch_Practising/01_06.01.2023_Torch_Manupulating_Matrices.ipynb#W2sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m#mean_column_of_a=torch.mean(a,axis=0)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/cihankatar/Desktop/Github_Repo/PyTorch_Practising/01_06.01.2023_Torch_Manupulating_Matrices.ipynb#W2sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m np_a\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marray([[\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m], \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cihankatar/Desktop/Github_Repo/PyTorch_Practising/01_06.01.2023_Torch_Manupulating_Matrices.ipynb#W2sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m             [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m10\u001b[39m]])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cihankatar/Desktop/Github_Repo/PyTorch_Practising/01_06.01.2023_Torch_Manupulating_Matrices.ipynb#W2sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mmean(np_a,axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cihankatar/Desktop/Github_Repo/PyTorch_Practising/01_06.01.2023_Torch_Manupulating_Matrices.ipynb#W2sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m tensor_a\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mtensor([[\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m], \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cihankatar/Desktop/Github_Repo/PyTorch_Practising/01_06.01.2023_Torch_Manupulating_Matrices.ipynb#W2sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m             [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m10\u001b[39m]],dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.tensor([[5,9],\n",
    "                [2,6],\n",
    "                [2,3]]) # 3x2 \n",
    "\n",
    "b=torch.rand(3,2)\n",
    "x=torch.tensor([[5,9,4],\n",
    "                [2,6,5],\n",
    "                      ]) # 2x3 \n",
    "\n",
    "elementwise = a*b    # element wise multiplication =3x2\n",
    "dotproduct  = a@x     # dot product     3x2  2x3 =3x3\n",
    "print(f'\\n elementwise a,b \\n',elementwise)\n",
    "print(f'\\n dotproduct a,x \\n=',dotproduct)\n",
    "\n",
    "c=torch.cat((a,b),dim=0)\n",
    "print(f'concatinating a and b in axis 0\\n',c)\n",
    "d=torch.cat((a,b),dim=1)\n",
    "print(f'\\nconcatinating a and b in axis 1\\n',d)\n",
    "\n",
    "print(\"a : {}\".format(a))\n",
    "\n",
    "slice_a= a[:,0]   # tensor([9, 6, 3])\n",
    "print(f' \\n slicing a[:,0] = ',slice_a.shape)\n",
    "slice_a_keep_dim=a[:,0:1]\n",
    "print(f' :\\n slice_a_keep_dim a[:, 0:1] = ',slice_a_keep_dim.shape)\n",
    "\n",
    "#Converting \n",
    "convert_numpy = a.numpy()\n",
    "convert_torch = torch.from_numpy(convert_numpy)\n",
    "type(convert_numpy), type(convert_torch)\n",
    "\n",
    "#sum for each of dim\n",
    "print(a)\n",
    "print(a.shape)\n",
    "sum=a.sum()\n",
    "print(f'\\nsum =', sum)\n",
    "sum_axis_keep_dim=a.sum(dim=1,keepdim=True)\n",
    "sum_axis=a.sum(dim=0)\n",
    "print(f'\\nsum and keep dim =',sum_axis_keep_dim)\n",
    "print(f'\\nsum and keep dim =',sum_axis)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#mean for each of dim ---------------------------------------------------\n",
    "#mean_column_of_a=torch.mean(a,axis=0)\n",
    "np_a=np.array([[1, 2, 3, 4], \n",
    "            [3, 4, 5, 10]])\n",
    "print(np.mean(np_a,axis=1))\n",
    "\n",
    "tensor_a=torch.tensor([[1, 2, 3, 4], \n",
    "            [3, 4, 5, 10]],dtype=torch.float)\n",
    "\n",
    "print(torch.mean(tensor_a,dim=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
